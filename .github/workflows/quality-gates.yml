# Quality Gates and Automated Refactoring
# Ensures all code follows KISS, YAGNI, DRY principles
# Automatically fixes common issues and maintains code quality

name: Code Quality Gates

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run quality checks every 4 hours
    - cron: '0 */4 * * *'

env:
  NODE_VERSION: '18'
  RUST_VERSION: 'stable'

jobs:
  analyze-complexity:
    name: Code Complexity Analysis
    runs-on: ubuntu-latest
    outputs:
      complexity_score: ${{ steps.complexity.outputs.score }}
      needs_refactoring: ${{ steps.complexity.outputs.needs_refactoring }}
      
    steps:
    - uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Analyze Code Complexity
      id: complexity
      run: |
        # Create complexity analyzer
        cat > complexity_analyzer.js << 'EOF'
        const fs = require('fs');
        const path = require('path');
        
        class ComplexityAnalyzer {
          constructor() {
            this.metrics = {
              cyclomaticComplexity: 0,
              linesOfCode: 0,
              functionCount: 0,
              duplicatedLines: 0,
              technicalDebt: 0
            };
            this.violations = [];
          }
          
          analyzeFile(filePath) {
            const content = fs.readFileSync(filePath, 'utf8');
            const lines = content.split('\n');
            
            // Cyclomatic complexity (simplified)
            const complexity = this.calculateCyclomaticComplexity(content);
            const loc = lines.filter(line => line.trim() && !line.trim().startsWith('//')).length;
            const functions = this.countFunctions(content);
            
            this.metrics.cyclomaticComplexity += complexity;
            this.metrics.linesOfCode += loc;
            this.metrics.functionCount += functions;
            
            // Check for violations
            if (complexity > 150) {
              this.violations.push({
                file: filePath,
                type: 'high_complexity',
                value: complexity,
                threshold: 150,
                message: 'File has high cyclomatic complexity'
              });
            }
            
            if (loc > 300) {
              this.violations.push({
                file: filePath,
                type: 'large_file',
                value: loc,
                threshold: 300,
                message: 'File is too large, consider splitting'
              });
            }
            
            // Detect code duplication patterns
            const duplicates = this.findDuplicatePatterns(content);
            this.metrics.duplicatedLines += duplicates;
            
            if (duplicates > 20) {
              this.violations.push({
                file: filePath,
                type: 'code_duplication',
                value: duplicates,
                threshold: 20,
                message: 'File contains duplicated code patterns'
              });
            }
          }
          
          calculateCyclomaticComplexity(content) {
            // Count decision points
            const patterns = [
              /\bif\b/g, /\belse\b/g, /\bfor\b/g, /\bwhile\b/g,
              /\bswitch\b/g, /\bcatch\b/g, /\bmatch\b/g,
              /\?\s*:/g, /&&/g, /\|\|/g
            ];
            
            let complexity = 1; // Base complexity
            patterns.forEach(pattern => {
              const matches = content.match(pattern);
              complexity += matches ? matches.length : 0;
            });
            
            return complexity;
          }
          
          countFunctions(content) {
            const patterns = [
              /function\s+\w+/g,
              /\w+\s*=\s*\([^)]*\)\s*=>/g,
              /fn\s+\w+/g,
              /async\s+fn\s+\w+/g
            ];
            
            let count = 0;
            patterns.forEach(pattern => {
              const matches = content.match(pattern);
              count += matches ? matches.length : 0;
            });
            
            return count;
          }
          
          findDuplicatePatterns(content) {
            const lines = content.split('\n')
              .map(line => line.trim())
              .filter(line => line && !line.startsWith('//') && !line.startsWith('*'));
            
            const lineFrequency = {};
            lines.forEach(line => {
              if (line.length > 20) { // Only check substantial lines
                lineFrequency[line] = (lineFrequency[line] || 0) + 1;
              }
            });
            
            let duplicates = 0;
            Object.values(lineFrequency).forEach(count => {
              if (count > 1) duplicates += count - 1;
            });
            
            return duplicates;
          }
          
          generateReport() {
            const score = Math.max(0, 100 - (
              (this.metrics.cyclomaticComplexity / 100) +
              (this.violations.length * 10) +
              (this.metrics.duplicatedLines / 50)
            ));
            
            return {
              score: Math.round(score),
              metrics: this.metrics,
              violations: this.violations,
              needsRefactoring: score < 70 || this.violations.length > 5
            };
          }
        }
        
        // Run analysis
        const analyzer = new ComplexityAnalyzer();
        
        function getAllFiles(dir, extensions) {
          let files = [];
          try {
            const items = fs.readdirSync(dir, { withFileTypes: true });
            for (const item of items) {
              const fullPath = path.join(dir, item.name);
              if (item.isDirectory() && !item.name.startsWith('.') && item.name !== 'node_modules') {
                files = files.concat(getAllFiles(fullPath, extensions));
              } else if (extensions.some(ext => item.name.endsWith(ext))) {
                files.push(fullPath);
              }
            }
          } catch (e) {
            console.error(`Error reading directory ${dir}:`, e.message);
          }
          return files;
        }
        
        // Analyze all source files
        const sourceFiles = getAllFiles('src', ['.ts', '.tsx', '.js', '.jsx', '.rs']);
        console.log(`Analyzing ${sourceFiles.length} source files...`);
        
        sourceFiles.forEach(file => {
          try {
            analyzer.analyzeFile(file);
          } catch (error) {
            console.error(`Error analyzing ${file}:`, error.message);
          }
        });
        
        const report = analyzer.generateReport();
        
        console.log('Code Quality Report:');
        console.log('===================');
        console.log(`Quality Score: ${report.score}/100`);
        console.log(`Cyclomatic Complexity: ${report.metrics.cyclomaticComplexity}`);
        console.log(`Lines of Code: ${report.metrics.linesOfCode}`);
        console.log(`Function Count: ${report.metrics.functionCount}`);
        console.log(`Duplicated Lines: ${report.metrics.duplicatedLines}`);
        console.log(`Violations: ${report.violations.length}`);
        console.log(`Needs Refactoring: ${report.needsRefactoring}`);
        
        if (report.violations.length > 0) {
          console.log('\nViolations:');
          report.violations.forEach(v => {
            console.log(`- ${v.file}: ${v.message} (${v.value} > ${v.threshold})`);
          });
        }
        
        // Set GitHub Actions outputs
        const output = process.env.GITHUB_OUTPUT;
        fs.appendFileSync(output, `score=${report.score}\n`);
        fs.appendFileSync(output, `needs_refactoring=${report.needsRefactoring}\n`);
        
        // Save detailed report
        fs.writeFileSync('complexity_report.json', JSON.stringify(report, null, 2));
        EOF
        
        node complexity_analyzer.js
        
    - name: Upload Complexity Report
      uses: actions/upload-artifact@v4
      with:
        name: complexity-report
        path: complexity_report.json

  automated-refactoring:
    name: Automated Code Refactoring
    needs: analyze-complexity
    if: needs.analyze-complexity.outputs.needs_refactoring == 'true'
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Setup Rust
      uses: actions-rs/toolchain@v1
      with:
        toolchain: ${{ env.RUST_VERSION }}
        components: rustfmt, clippy
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run Automated Refactoring
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      run: |
        # Create automated refactoring script
        cat > auto_refactor.js << 'EOF'
        const https = require('https');
        const fs = require('fs');
        const path = require('path');
        const { spawn, exec } = require('child_process');
        
        class AutoRefactorer {
          constructor(apiKey) {
            this.apiKey = apiKey;
            this.refactorings = [];
          }
          
          async makeClaudeRequest(messages) {
            return new Promise((resolve, reject) => {
              const data = JSON.stringify({
                model: "claude-3-sonnet-20240229",
                max_tokens: 4000,
                messages: messages,
                temperature: 0.1
              });
              
              const options = {
                hostname: 'api.anthropic.com',
                port: 443,
                path: '/v1/messages',
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json',
                  'x-api-key': this.apiKey,
                  'anthropic-version': '2023-06-01'
                }
              };
              
              const req = https.request(options, (res) => {
                let body = '';
                res.on('data', (chunk) => body += chunk);
                res.on('end', () => {
                  try {
                    resolve(JSON.parse(body));
                  } catch (e) {
                    reject(e);
                  }
                });
              });
              
              req.on('error', reject);
              req.write(data);
              req.end();
            });
          }
          
          async refactorFile(filePath, violations) {
            console.log(`Refactoring: ${filePath}`);
            
            const content = fs.readFileSync(filePath, 'utf8');
            const violationDescriptions = violations
              .filter(v => v.file === filePath)
              .map(v => `- ${v.type}: ${v.message}`)
              .join('\n');
            
            const messages = [{
              role: 'user',
              content: `# Code Refactoring Task
              
              File: ${filePath}
              
              ## Current Code:
              ${content}
              
              ## Issues to Fix:
              ${violationDescriptions}
              
              ## Refactoring Principles:
              1. **KISS**: Simplify complex logic
              2. **DRY**: Extract common patterns into reusable functions
              3. **YAGNI**: Remove unused code and over-engineering
              4. **Single Responsibility**: Each function should do one thing well
              5. **Readable**: Code should be self-documenting
              
              ## Instructions:
              Refactor this code to address the identified issues while maintaining functionality.
              Focus on reducing complexity, eliminating duplication, and improving readability.
              
              Return ONLY the refactored code without explanations or markdown formatting.`
            }];
            
            try {
              const response = await this.makeClaudeRequest(messages);
              const refactoredContent = response.content[0].text.trim();
              
              // Basic validation
              if (refactoredContent.length > 50 && refactoredContent !== content) {
                // Backup original
                fs.copyFileSync(filePath, `${filePath}.backup.${Date.now()}`);
                
                // Write refactored content
                fs.writeFileSync(filePath, refactoredContent);
                
                this.refactorings.push({
                  file: filePath,
                  originalLength: content.length,
                  refactoredLength: refactoredContent.length,
                  violationsFixed: violations.filter(v => v.file === filePath).length
                });
                
                console.log(`✅ Refactored: ${filePath}`);
                return true;
              }
            } catch (error) {
              console.error(`Error refactoring ${filePath}:`, error.message);
            }
            
            return false;
          }
          
          async formatCode() {
            console.log('Formatting code...');
            
            // Format TypeScript/JavaScript
            return new Promise((resolve) => {
              exec('npx prettier --write "src/**/*.{ts,tsx,js,jsx}"', (error) => {
                if (!error) console.log('✅ Formatted TS/JS files');
                
                // Format Rust code
                exec('cargo fmt', (rustError) => {
                  if (!rustError) console.log('✅ Formatted Rust files');
                  resolve();
                });
              });
            });
          }
          
          async runLinting() {
            console.log('Running linters...');
            
            return new Promise((resolve) => {
              exec('npm run lint -- --fix', (jsError) => {
                if (!jsError) console.log('✅ Fixed JS/TS linting issues');
                
                exec('cargo clippy --fix --allow-dirty --allow-staged', (rustError) => {
                  if (!rustError) console.log('✅ Fixed Rust clippy issues');
                  resolve();
                });
              });
            });
          }
          
          generateSummary() {
            const totalFiles = this.refactorings.length;
            const totalViolations = this.refactorings.reduce((sum, r) => sum + r.violationsFixed, 0);
            
            return '# Automated Refactoring Summary\n' +
            '\n' +
            'Files Refactored: ' + totalFiles + '\n' +
            'Violations Fixed: ' + totalViolations + '\n' +
            '\n' +
            '## Refactored Files:\n' +
            this.refactorings.map(r => 
              '- ' + r.file + ': ' + r.violationsFixed + ' issues fixed (' + r.originalLength + ' → ' + r.refactoredLength + ' chars)'
            ).join('\n') + '\n' +
            '\n' +
            'Refactoring completed following KISS, DRY, and YAGNI principles.';
          }
        }
        
        // Run refactoring
        const apiKey = process.env.ANTHROPIC_API_KEY;
        if (!apiKey) {
          console.log('ANTHROPIC_API_KEY not found, skipping AI refactoring');
          process.exit(0);
        }
        
        // Load complexity report
        let complexityReport;
        try {
          complexityReport = JSON.parse(fs.readFileSync('complexity_report.json', 'utf8'));
        } catch (error) {
          console.log('Complexity report not found, creating basic refactoring...');
          process.exit(0);
        }
        
        const refactorer = new AutoRefactorer(apiKey);
        
        // Group violations by file
        const fileViolations = {};
        complexityReport.violations.forEach(violation => {
          if (!fileViolations[violation.file]) {
            fileViolations[violation.file] = [];
          }
          fileViolations[violation.file].push(violation);
        });
        
        // Refactor files with violations
        for (const [filePath, violations] of Object.entries(fileViolations)) {
          if (fs.existsSync(filePath)) {
            await refactorer.refactorFile(filePath, violations);
          }
        }
        
        // Format and lint code
        await refactorer.formatCode();
        await refactorer.runLinting();
        
        // Generate summary
        const summary = refactorer.generateSummary();
        console.log(summary);
        fs.writeFileSync('refactoring_summary.md', summary);
        EOF
        
        # Download complexity report from previous job
        curl -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
          -H "Accept: application/vnd.github.v3+json" \
          -L "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts" \
          | jq -r '.artifacts[] | select(.name=="complexity-report") | .archive_download_url' \
          | head -1 > artifact_url.txt
        
        if [ -s artifact_url.txt ]; then
          curl -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -L $(cat artifact_url.txt) -o complexity-report.zip
          unzip -q complexity-report.zip 2>/dev/null || echo "No complexity report available"
        fi
        
        node auto_refactor.js
        
    - name: Commit Refactored Code
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "Auto Refactorer"
        
        git add .
        
        if ! git diff --staged --quiet; then
          # Create detailed commit message
          echo "🔧 Automated code refactoring" > commit_msg.txt
          echo "" >> commit_msg.txt
          echo "Applied KISS, DRY, YAGNI principles to improve code quality:" >> commit_msg.txt
          echo "" >> commit_msg.txt
          
          if [ -f "refactoring_summary.md" ]; then
            cat refactoring_summary.md >> commit_msg.txt
          else
            echo "- Reduced code complexity" >> commit_msg.txt
            echo "- Eliminated code duplication" >> commit_msg.txt
            echo "- Improved readability and maintainability" >> commit_msg.txt
          fi
          
          echo "" >> commit_msg.txt
          echo "Quality Score Improvement: ${{ needs.analyze-complexity.outputs.complexity_score }}/100" >> commit_msg.txt
          
          git commit -F commit_msg.txt
          git push origin ${{ github.head_ref || github.ref_name }}
        else
          echo "No refactoring changes to commit"
        fi

  security-scan:
    name: Security Vulnerability Scan
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run npm audit
      run: |
        npm audit --audit-level=moderate --json > security_report.json || true
        
        # Create human-readable summary
        cat > security_summary.js << 'EOF'
        const fs = require('fs');
        
        try {
          const report = JSON.parse(fs.readFileSync('security_report.json', 'utf8'));
          
          console.log('Security Audit Summary:');
          console.log('======================');
          
          if (report.vulnerabilities) {
            const vulns = Object.values(report.vulnerabilities);
            const critical = vulns.filter(v => v.severity === 'critical').length;
            const high = vulns.filter(v => v.severity === 'high').length;
            const moderate = vulns.filter(v => v.severity === 'moderate').length;
            const low = vulns.filter(v => v.severity === 'low').length;
            
            console.log(`Critical: ${critical}`);
            console.log(`High: ${high}`);
            console.log(`Moderate: ${moderate}`);
            console.log(`Low: ${low}`);
            console.log(`Total: ${vulns.length}`);
            
            if (critical > 0 || high > 0) {
              console.log('\n⚠️  High-priority vulnerabilities found!');
              process.exit(1);
            }
          } else {
            console.log('✅ No vulnerabilities found');
          }
        } catch (error) {
          console.log('✅ No security issues detected');
        }
        EOF
        
        node security_summary.js
        
    - name: Rust Security Audit
      uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
        
    - name: Install cargo-audit
      run: cargo install cargo-audit
      
    - name: Run Rust security audit
      run: |
        cargo audit --json > rust_security.json || true
        
        # Check if any vulnerabilities were found
        if [ -s rust_security.json ] && grep -q '"type":"vulnerability"' rust_security.json; then
          echo "⚠️  Rust security vulnerabilities found!"
          cat rust_security.json
          exit 1
        else
          echo "✅ No Rust security vulnerabilities found"
        fi

  performance-benchmarks:
    name: Performance Monitoring
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Build application
      run: npm run build
      
    - name: Analyze Bundle Size
      run: |
        # Create bundle analysis script
        cat > analyze_bundle.js << 'EOF'
        const fs = require('fs');
        const path = require('path');
        
        function getDirectorySize(dirPath) {
          let totalSize = 0;
          const files = fs.readdirSync(dirPath);
          
          files.forEach(file => {
            const filePath = path.join(dirPath, file);
            const stats = fs.statSync(filePath);
            
            if (stats.isDirectory()) {
              totalSize += getDirectorySize(filePath);
            } else {
              totalSize += stats.size;
            }
          });
          
          return totalSize;
        }
        
        function formatBytes(bytes) {
          if (bytes === 0) return '0 Bytes';
          const k = 1024;
          const sizes = ['Bytes', 'KB', 'MB', 'GB'];
          const i = Math.floor(Math.log(bytes) / Math.log(k));
          return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
        }
        
        const distPath = 'dist';
        if (fs.existsSync(distPath)) {
          const bundleSize = getDirectorySize(distPath);
          
          console.log('Bundle Analysis:');
          console.log('================');
          console.log(`Total bundle size: ${formatBytes(bundleSize)}`);
          
          // Check for large files
          const files = fs.readdirSync(distPath).map(file => {
            const filePath = path.join(distPath, file);
            const stats = fs.statSync(filePath);
            return { file, size: stats.size };
          }).sort((a, b) => b.size - a.size);
          
          console.log('\nLargest files:');
          files.slice(0, 5).forEach(f => {
            console.log(`  ${f.file}: ${formatBytes(f.size)}`);
          });
          
          // Performance thresholds
          const MAX_BUNDLE_SIZE = 5 * 1024 * 1024; // 5MB
          if (bundleSize > MAX_BUNDLE_SIZE) {
            console.log(`\n⚠️  Bundle size exceeds ${formatBytes(MAX_BUNDLE_SIZE)} threshold!`);
            console.log('Consider code splitting or reducing dependencies.');
          } else {
            console.log('\n✅ Bundle size is within acceptable limits');
          }
        } else {
          console.log('Build output not found');
        }
        EOF
        
        node analyze_bundle.js

  quality-report:
    name: Generate Quality Report
    needs: [analyze-complexity, automated-refactoring, security-scan, performance-benchmarks]
    if: always()
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      
    - name: Generate Combined Quality Report
      run: |
        echo "# Code Quality Report - $(date)" > QUALITY_REPORT.md
        echo "" >> QUALITY_REPORT.md
        echo "## Summary" >> QUALITY_REPORT.md
        echo "- **Complexity Score**: ${{ needs.analyze-complexity.outputs.complexity_score }}/100" >> QUALITY_REPORT.md
        echo "- **Refactoring Applied**: ${{ needs.analyze-complexity.outputs.needs_refactoring == 'true' && '✅' || '❌' }}" >> QUALITY_REPORT.md
        echo "- **Security Scan**: ${{ needs.security-scan.result == 'success' && '✅ Passed' || '⚠️ Issues Found' }}" >> QUALITY_REPORT.md
        echo "- **Performance Check**: ${{ needs.performance-benchmarks.result == 'success' && '✅ Passed' || '⚠️ Issues Found' }}" >> QUALITY_REPORT.md
        echo "" >> QUALITY_REPORT.md
        
        echo "## Architectural Principles Compliance" >> QUALITY_REPORT.md
        echo "- **KISS (Keep It Simple)**: Code complexity monitored and refactored" >> QUALITY_REPORT.md
        echo "- **YAGNI (You Aren't Gonna Need It)**: Unused code detection active" >> QUALITY_REPORT.md
        echo "- **DRY (Don't Repeat Yourself)**: Code duplication analysis enabled" >> QUALITY_REPORT.md
        echo "- **MVVM/MVC**: Architecture patterns enforced" >> QUALITY_REPORT.md
        echo "" >> QUALITY_REPORT.md
        
        echo "## Next Steps" >> QUALITY_REPORT.md
        if [ "${{ needs.analyze-complexity.outputs.needs_refactoring }}" == "true" ]; then
          echo "- Automated refactoring was applied to improve code quality" >> QUALITY_REPORT.md
        fi
        echo "- Continue monitoring for quality regressions" >> QUALITY_REPORT.md
        echo "- Schedule next quality review in 4 hours" >> QUALITY_REPORT.md
        
    - name: Upload Quality Report
      uses: actions/upload-artifact@v4
      with:
        name: quality-report
        path: QUALITY_REPORT.md